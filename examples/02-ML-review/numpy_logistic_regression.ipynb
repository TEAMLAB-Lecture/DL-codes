{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# 재현성을 위한 시드 설정\n",
    "np.random.seed(42)\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "def load_and_preprocess_diabetes_data():\n",
    "    \"\"\"당뇨병 데이터셋 로드 및 전처리\"\"\"\n",
    "    # 데이터 로드\n",
    "    diabetes = load_diabetes()\n",
    "    X = diabetes.data\n",
    "    y = diabetes.target\n",
    "    \n",
    "    # 당뇨병 진단 기준에 따라 이진 분류로 변환 (중간값 기준)\n",
    "    y_binary = (y > np.median(y)).astype(int)\n",
    "    \n",
    "    # 특성 이름 설정\n",
    "    feature_names = diabetes.feature_names\n",
    "    \n",
    "    # 특성 엔지니어링\n",
    "    # 1. BMI와 혈압의 상호작용\n",
    "    bmi_idx = np.where(feature_names == 'bmi')[0][0]\n",
    "    bp_idx = np.where(feature_names == 'bp')[0][0]\n",
    "    X = np.column_stack([X, X[:, bmi_idx] * X[:, bp_idx]])\n",
    "    feature_names = np.append(feature_names, 'bmi_bp_interaction')\n",
    "    \n",
    "    # 2. BMI의 제곱\n",
    "    X = np.column_stack([X, X[:, bmi_idx]**2])\n",
    "    feature_names = np.append(feature_names, 'bmi_squared')\n",
    "    \n",
    "    # 데이터 정규화\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, y_binary, feature_names, scaler\n",
    "\n",
    "# 로지스틱 회귀 모델 클래스\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.1, num_iterations=1000, verbose=True):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.verbose = verbose\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.test_accuracies = []\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"시그모이드 함수: 1 / (1 + exp(-z))\"\"\"\n",
    "        # 오버플로우/언더플로우 방지를 위한 클리핑\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def initialize_parameters(self, n_features):\n",
    "        \"\"\"가중치와 편향 초기화\"\"\"\n",
    "        self.weights = np.random.randn(n_features) * 0.01\n",
    "        self.bias = 0\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"순방향 전파: z = X·w + b, a = sigmoid(z)\"\"\"\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.sigmoid(z)\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        \"\"\"이진 교차 엔트로피 손실 계산\"\"\"\n",
    "        # 수치적 안정성을 위한 클리핑\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        # 손실 계산: -[y·log(p) + (1-y)·log(1-p)]\n",
    "        loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        return loss\n",
    "    \n",
    "    def compute_gradients(self, X, y_true, y_pred):\n",
    "        \"\"\"경사 계산: dL/dw, dL/db\"\"\"\n",
    "        m = X.shape[0]\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y_true))\n",
    "        db = (1/m) * np.sum(y_pred - y_true)\n",
    "        return dw, db\n",
    "    \n",
    "    def update_parameters(self, dw, db):\n",
    "        \"\"\"경사 하강법을 사용한 가중치와 편향 업데이트\"\"\"\n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"확률 예측\"\"\"\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"클래스 예측\"\"\"\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_test=None, y_test=None):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        # 파라미터 초기화\n",
    "        n_features = X_train.shape[1]\n",
    "        self.initialize_parameters(n_features)\n",
    "        \n",
    "        # 학습 과정\n",
    "        for i in range(self.num_iterations):\n",
    "            # 순방향 전파\n",
    "            y_pred = self.forward(X_train)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = self.compute_loss(y_train, y_pred)\n",
    "            self.losses.append(loss)\n",
    "            \n",
    "            # 경사 계산\n",
    "            dw, db = self.compute_gradients(X_train, y_train, y_pred)\n",
    "            \n",
    "            # 파라미터 업데이트\n",
    "            self.update_parameters(dw, db)\n",
    "            \n",
    "            # 학습/테스트 정확도 계산\n",
    "            train_accuracy = np.mean((self.predict(X_train) == y_train).astype(int))\n",
    "            self.train_accuracies.append(train_accuracy)\n",
    "            \n",
    "            if X_test is not None and y_test is not None:\n",
    "                test_accuracy = np.mean((self.predict(X_test) == y_test).astype(int))\n",
    "                self.test_accuracies.append(test_accuracy)\n",
    "            \n",
    "            # 진행 상황 출력\n",
    "            if self.verbose and (i+1) % 100 == 0:\n",
    "                if X_test is not None and y_test is not None:\n",
    "                    print(f'에폭 {i+1}/{self.num_iterations}, '\n",
    "                          f'손실: {loss:.4f}, '\n",
    "                          f'학습 정확도: {train_accuracy:.4f}, '\n",
    "                          f'테스트 정확도: {test_accuracy:.4f}')\n",
    "                else:\n",
    "                    print(f'에폭 {i+1}/{self.num_iterations}, '\n",
    "                          f'손실: {loss:.4f}, '\n",
    "                          f'학습 정확도: {train_accuracy:.4f}')\n",
    "        \n",
    "        return self\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "X_scaled, y, feature_names, scaler = load_and_preprocess_diabetes_data()\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"특성 목록:\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"{i+1}. {name}\")\n",
    "\n",
    "print(\"\\n클래스 분포:\")\n",
    "print(pd.Series(y).value_counts(normalize=True))\n",
    "\n",
    "# 학습/테스트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 교차 검증\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(LogisticRegression(verbose=False), X_scaled, y, cv=kf, scoring='accuracy')\n",
    "print(\"\\n교차 검증 정확도:\", cv_scores)\n",
    "print(\"평균 교차 검증 정확도:\", np.mean(cv_scores))\n",
    "print(\"교차 검증 정확도 표준편차:\", np.std(cv_scores))\n",
    "\n",
    "# 로지스틱 회귀 모델 학습\n",
    "model = LogisticRegression(learning_rate=0.1, num_iterations=1000)\n",
    "model.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# 기본 평가 지표\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== 모델 평가 결과 ===\")\n",
    "print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"정밀도 (Precision): {precision:.4f}\")\n",
    "print(f\"재현율 (Recall): {recall:.4f}\")\n",
    "print(f\"F1 스코어: {f1:.4f}\")\n",
    "\n",
    "# ROC 커브\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 결과 시각화\n",
    "# 1. 손실 그래프\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(model.losses, label='손실')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('손실 (BCE)')\n",
    "plt.title('학습 손실')\n",
    "plt.legend()\n",
    "\n",
    "# 2. 정확도 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model.train_accuracies, label='학습 정확도')\n",
    "plt.plot(model.test_accuracies, label='테스트 정확도')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.title('학습 및 테스트 정확도')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('numpy_logistic_regression_learning_curves.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. 혼동 행렬\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['정상', '당뇨병'], \n",
    "            yticklabels=['정상', '당뇨병'])\n",
    "plt.xlabel('예측 레이블')\n",
    "plt.ylabel('실제 레이블')\n",
    "plt.title('혼동 행렬 (Confusion Matrix)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('numpy_logistic_regression_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. ROC 커브\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC 커브 (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('numpy_logistic_regression_roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 5. 가중치 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['blue' if w > 0 else 'red' for w in model.weights]\n",
    "plt.bar(feature_names, model.weights, color=colors)\n",
    "plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.xlabel('특성')\n",
    "plt.ylabel('가중치')\n",
    "plt.title('로지스틱 회귀 모델의 학습된 가중치')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('numpy_logistic_regression_weights.png')\n",
    "plt.close()\n",
    "\n",
    "# 6. 결정 경계 시각화 (PCA 사용)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_pca[y == 0, 0], X_pca[y == 0, 1], label='정상', alpha=0.6)\n",
    "plt.scatter(X_pca[y == 1, 0], X_pca[y == 1, 1], label='당뇨병', alpha=0.6)\n",
    "\n",
    "# 격자 생성\n",
    "h = 0.01\n",
    "x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# PCA 역변환 (2D -> 원래 차원)\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "grid_original = pca.inverse_transform(grid)\n",
    "\n",
    "# 예측\n",
    "Z = model.predict_proba(grid_original).reshape(xx.shape)\n",
    "\n",
    "# 결정 경계 그리기\n",
    "plt.contour(xx, yy, Z, levels=[0.5], colors='k', linestyles='-')\n",
    "plt.colorbar(plt.contourf(xx, yy, Z, alpha=0.2, cmap='RdBu'))\n",
    "\n",
    "plt.xlabel('주성분 1')\n",
    "plt.ylabel('주성분 2')\n",
    "plt.title('PCA로 시각화한 로지스틱 회귀 결정 경계')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('numpy_logistic_regression_decision_boundary.png')\n",
    "plt.close()\n",
    "\n",
    "# 7. 로지스틱 회귀의 수학적 개념 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 1. 시그모이드 함수\n",
    "plt.subplot(1, 3, 1)\n",
    "z = np.linspace(-10, 10, 1000)\n",
    "sigmoid = 1 / (1 + np.exp(-z))\n",
    "plt.plot(z, sigmoid)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.title('시그모이드 함수')\n",
    "plt.xlabel('z = w·x + b')\n",
    "plt.ylabel('σ(z) = 1 / (1 + e^(-z))')\n",
    "plt.grid(True)\n",
    "\n",
    "# 2. 로그 오즈\n",
    "plt.subplot(1, 3, 2)\n",
    "p = np.linspace(0.01, 0.99, 1000)\n",
    "log_odds = np.log(p / (1 - p))\n",
    "plt.plot(p, log_odds)\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=0.5, color='r', linestyle='--', alpha=0.3)\n",
    "plt.title('로그 오즈 함수')\n",
    "plt.xlabel('확률 (p)')\n",
    "plt.ylabel('log(p/(1-p))')\n",
    "plt.grid(True)\n",
    "\n",
    "# 3. 이진 교차 엔트로피 손실\n",
    "plt.subplot(1, 3, 3)\n",
    "p = np.linspace(0.01, 0.99, 1000)\n",
    "bce_loss_y1 = -np.log(p)\n",
    "bce_loss_y0 = -np.log(1 - p)\n",
    "plt.plot(p, bce_loss_y1, label='y=1')\n",
    "plt.plot(p, bce_loss_y0, label='y=0')\n",
    "plt.title('이진 교차 엔트로피 손실')\n",
    "plt.xlabel('예측 확률 (p)')\n",
    "plt.ylabel('-log(p) or -log(1-p)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('numpy_logistic_regression_concept_visualization.png')\n",
    "plt.close()\n",
    "\n",
    "# 새로운 환자 데이터로 예측 예시\n",
    "print(\"\\n=== 새로운 환자 데이터에 대한 예측 ===\")\n",
    "# 임의의 새 환자 데이터 생성 (원본 특성만)\n",
    "new_patients = np.array([\n",
    "    # age, sex, bmi, bp, s1, s2, s3, s4, s5, s6\n",
    "    [0.5, 0.8, 2.0, 0.6, 0.7, 1.0, -0.5, 0.3, 0.4, 0.2],  # 고위험 환자\n",
    "    [0.2, 0.3, 0.1, 0.2, 0.1, 0.0, 0.5, -0.1, 0.2, 0.1]   # 저위험 환자\n",
    "])\n",
    "\n",
    "# 특성 엔지니어링 적용\n",
    "bmi_idx = np.where(feature_names == 'bmi')[0][0]\n",
    "bp_idx = np.where(feature_names == 'bp')[0][0]\n",
    "new_patients = np.column_stack([\n",
    "    new_patients,\n",
    "    new_patients[:, bmi_idx] * new_patients[:, bp_idx],  # BMI와 혈압의 상호작용\n",
    "    new_patients[:, bmi_idx]**2  # BMI의 제곱\n",
    "])\n",
    "\n",
    "# 데이터 정규화\n",
    "new_patients_scaled = scaler.transform(new_patients)\n",
    "\n",
    "# 예측\n",
    "probabilities = model.predict_proba(new_patients_scaled)\n",
    "predictions = model.predict(new_patients_scaled)\n",
    "\n",
    "# 결과 출력\n",
    "for i, (prob, pred) in enumerate(zip(probabilities, predictions)):\n",
    "    risk_level = \"고위험\" if i == 0 else \"저위험\"\n",
    "    print(f\"{risk_level} 환자:\")\n",
    "    print(f\"  당뇨병 확률: {prob:.4f}\")\n",
    "    print(f\"  예측 클래스: {'당뇨병' if pred == 1 else '정상'}\")\n",
    "\n",
    "# 모델 해석\n",
    "print(\"\\n=== 모델 해석: 특성 중요도 ===\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    '특성': feature_names,\n",
    "    '가중치': model.weights,\n",
    "    '절대값': np.abs(model.weights)\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('절대값', ascending=False)\n",
    "print(feature_importance)\n",
    "\n",
    "print(\"\\n=== 로그 오즈비 해석 ===\")\n",
    "print(\"로지스틱 회귀에서 가중치는 로그 오즈비를 나타냅니다.\")\n",
    "for feature, weight in zip(feature_names, model.weights):\n",
    "    odds_change = np.exp(weight) - 1\n",
    "    direction = \"증가\" if weight > 0 else \"감소\"\n",
    "    print(f\"{feature}: 1 단위 증가 시 당뇨병 오즈가 {abs(odds_change)*100:.2f}% {direction}\")\n",
    "\n",
    "# 다양한 임계값에 따른 성능 평가\n",
    "thresholds = np.arange(0.1, 0.9, 0.1)\n",
    "results = []\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred_threshold)\n",
    "    precision = precision_score(y_test, y_pred_threshold)\n",
    "    recall = recall_score(y_test, y_pred_threshold)\n",
    "    f1 = f1_score(y_test, y_pred_threshold)\n",
    "    results.append({\n",
    "        '임계값': threshold,\n",
    "        '정확도': accuracy,\n",
    "        '정밀도': precision,\n",
    "        '재현율': recall,\n",
    "        'F1': f1\n",
    "    })\n",
    "\n",
    "print(\"\\n=== 다양한 임계값에 따른 성능 평가 ===\")\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
