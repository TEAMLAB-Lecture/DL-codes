{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f88aba",
   "metadata": {},
   "source": [
    "# PyTorch와 Weights & Biases를 활용한 딥러닝 모델 모니터링\n",
    "\n",
    "이 노트북은 PyTorch로 딥러닝 모델을 학습하면서 Weights & Biases(W&B)를 활용해 학습 과정을 모니터링하는 방법을 단계별로 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8f7c9",
   "metadata": {},
   "source": [
    "## 1. 필요한 라이브러리 설치\n",
    "\n",
    "먼저 필요한 라이브러리를 설치합니다. 실행 중 에러가 발생하면 이 셀을 실행해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb402f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치 (처음 실행할 때만 필요)\n",
    "!pip install wandb tqdm matplotlib\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b3735",
   "metadata": {},
   "source": [
    "## 2. 라이브러리 임포트 및 버전 확인\n",
    "\n",
    "필요한 라이브러리를 임포트하고 버전을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d529a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 버전 확인\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "    print(f\"사용 가능한 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# matplotlib 인라인 모드 설정\n",
    "# %matplotlib inline # .py 파일에서는 주석 처리하거나 제거해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdb914",
   "metadata": {},
   "source": [
    "## 3. 기본 설정\n",
    "\n",
    "학습에 사용할 기본 설정값을 정의합니다. 필요에 따라 이 값들을 조정해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c06f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정값 지정 - 여기서 값을 변경하여 실험해보세요\n",
    "config = {\n",
    "    \"learning_rate\": 0.001,  # 학습률\n",
    "    \"batch_size\": 32,      # 배치 크기\n",
    "    \"epochs\": 5,           # 에폭 수\n",
    "    \"model\": \"ResNet18\",   # 모델 아키텍처\n",
    "    \"optimizer\": \"Adam\",   # 옵티마이저\n",
    "    \"loss\": \"CrossEntropyLoss\",  # 손실 함수\n",
    "    \"num_workers\": 2,      # 데이터 로딩에 사용할 스레드 수\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 학습 장치\n",
    "}\n",
    "\n",
    "print(f\"학습 설정:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"- {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5f9b4",
   "metadata": {},
   "source": [
    "## 4. 데이터 시각화 함수\n",
    "\n",
    "데이터를 시각적으로 확인하기 위한 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f570b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataloader, classes, num_samples=8):\n",
    "    \"\"\"\n",
    "    데이터로더에서 샘플 이미지를 시각화합니다.\n",
    "\n",
    "    Args:\n",
    "        dataloader: 데이터로더\n",
    "        classes: 클래스 이름 목록\n",
    "        num_samples: 표시할 샘플 수\n",
    "    \"\"\"\n",
    "    # 배치 하나를 가져옵니다\n",
    "    images, labels = next(iter(dataloader))\n",
    "\n",
    "    # 이미지와 레이블을 선택합니다\n",
    "    images = images[:num_samples]\n",
    "    labels = labels[:num_samples]\n",
    "\n",
    "    # 이미지 역정규화\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    # 역정규화를 위한 reshape\n",
    "    mean = mean.view(1, 3, 1, 1)\n",
    "    std = std.view(1, 3, 1, 1)\n",
    "\n",
    "    images_denorm = images.clone() * std + mean # 브로드캐스팅 활용\n",
    "\n",
    "    # 이미지 시각화\n",
    "    fig, axes = plt.subplots(2, num_samples//2, figsize=(15, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (img, label) in enumerate(zip(images_denorm, labels)):\n",
    "        # 텐서 채널 순서 변경 (C, H, W) -> (H, W, C) for matplotlib\n",
    "        img_display = img.permute(1, 2, 0).numpy()\n",
    "        # 값 범위 [0, 1]로 클리핑\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "\n",
    "        axes[i].imshow(img_display)\n",
    "        axes[i].set_title(f\"클래스: {classes[label]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bbeff",
   "metadata": {},
   "source": [
    "## 5. 데이터 준비\n",
    "\n",
    "CIFAR-10 데이터셋을 다운로드하고 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환 정의\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# CIFAR-10 데이터셋 로드\n",
    "# 데이터셋 로드 시 에러 발생하면 download=True 유지, 이후 실행 시 False로 변경 가능\n",
    "try:\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "    val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transform)\n",
    "except Exception as e:\n",
    "    print(f\"데이터셋 다운로드/로드 중 오류 발생: {e}\")\n",
    "    print(\"기존 데이터가 있다면 download=False 로 시도해보세요.\")\n",
    "    # 필요한 경우 여기서 exit() 또는 다른 오류 처리\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    pin_memory=True if config[\"device\"] == \"cuda\" else False # GPU 사용 시 pin_memory=True 권장\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    pin_memory=True if config[\"device\"] == \"cuda\" else False\n",
    ")\n",
    "\n",
    "# 클래스 이름\n",
    "classes = ['비행기', '자동차', '새', '고양이', '사슴', '개', '개구리', '말', '배', '트럭']\n",
    "\n",
    "print(f\"학습 데이터셋: {len(train_dataset)} 이미지\")\n",
    "print(f\"검증 데이터셋: {len(val_dataset)} 이미지\")\n",
    "print(f\"클래스: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5634b",
   "metadata": {},
   "source": [
    "## 6. 데이터 샘플 시각화\n",
    "\n",
    "학습 데이터의 일부를 시각화하여 확인해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 샘플 시각화 (데이터 로더가 정상 생성되었을 때만 실행)\n",
    "if 'train_loader' in locals():\n",
    "     visualize_samples(train_loader, classes)\n",
    "else:\n",
    "     print(\"학습 데이터 로더가 준비되지 않아 시각화를 건너<0xEB>고 뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ea52d",
   "metadata": {},
   "source": [
    "## 7. WandbMonitor 클래스 정의\n",
    "\n",
    "Weights & Biases를 활용한 모니터링을 위한 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbMonitor:\n",
    "    def __init__(self, project_name, config):\n",
    "        \"\"\"\n",
    "        W&B 모니터링 초기화\n",
    "\n",
    "        Args:\n",
    "            project_name (str): W&B 프로젝트 이름\n",
    "            config (dict): 설정 딕셔너리\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # W&B 초기화\n",
    "            self.run = wandb.init(\n",
    "                project=project_name,\n",
    "                config=config,\n",
    "                name=f\"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "                reinit=True # 혹시 모를 중복 초기화 방지\n",
    "            )\n",
    "            print(f\"W&B Run 시작: {self.run.name} (Project: {project_name})\")\n",
    "            # 설정 저장\n",
    "            self.config = wandb.config\n",
    "        except Exception as e:\n",
    "            print(f\"W&B 초기화 중 오류 발생: {e}\")\n",
    "            print(\"W&B 로그인이 되어있는지, API 키가 유효한지 확인하세요.\")\n",
    "            self.run = None # 초기화 실패 시 run 객체 None 설정\n",
    "            self.config = config # 기본 config 유지\n",
    "\n",
    "    def watch_model(self, model, log_freq=100):\n",
    "        \"\"\" 그라디언트 로깅을 위한 모델 감시 \"\"\"\n",
    "        if self.run: # run이 성공적으로 초기화되었을 때만 실행\n",
    "            try:\n",
    "                wandb.watch(model, log=\"all\", log_freq=log_freq) # log=\"all\" 로 가중치/그라디언트 모두 로깅\n",
    "            except Exception as e:\n",
    "                 print(f\"W&B 모델 감시 중 오류: {e}\")\n",
    "\n",
    "\n",
    "    def log_metrics(self, metrics, step=None):\n",
    "        \"\"\" 메트릭을 W&B에 로깅 \"\"\"\n",
    "        if self.run:\n",
    "            try:\n",
    "                wandb.log(metrics, step=step)\n",
    "            except Exception as e:\n",
    "                 print(f\"W&B 메트릭 로깅 중 오류: {e}\")\n",
    "\n",
    "\n",
    "    def log_images(self, images, name=\"images\", captions=None):\n",
    "       \"\"\" 이미지를 W&B에 로깅 \"\"\"\n",
    "       if self.run:\n",
    "            try:\n",
    "                # 이미지 텐서 처리 (CPU 이동, numpy 변환, 정규화 복원 대신 [0,1] 클램핑)\n",
    "                images_to_log = images.cpu().clone() # 원본 변경 방지 위해 clone\n",
    "                # 역정규화 (시각화 함수와 유사하게)\n",
    "                mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "                std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "                images_to_log = images_to_log * std + mean\n",
    "                images_to_log = torch.clamp(images_to_log, 0, 1) # [0, 1] 범위로 클램핑\n",
    "\n",
    "                wandb_images = []\n",
    "                for i, img_tensor in enumerate(images_to_log):\n",
    "                    caption = captions[i] if captions and i < len(captions) else None\n",
    "                    wandb_images.append(wandb.Image(img_tensor, caption=caption))\n",
    "\n",
    "                wandb.log({name: wandb_images})\n",
    "            except Exception as e:\n",
    "                print(f\"W&B 이미지 로깅 중 오류: {e}\")\n",
    "\n",
    "\n",
    "    def log_confusion_matrix(self, y_true, y_pred, class_names):\n",
    "        \"\"\" 혼동 행렬을 W&B에 로깅 \"\"\"\n",
    "        if self.run:\n",
    "             try:\n",
    "                wandb.log({\n",
    "                    \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                        y_true=y_true,\n",
    "                        preds=y_pred,\n",
    "                        class_names=class_names\n",
    "                    )\n",
    "                })\n",
    "             except Exception as e:\n",
    "                 print(f\"W&B 혼동 행렬 로깅 중 오류: {e}\")\n",
    "\n",
    "\n",
    "    def log_learning_rate(self, optimizer, step):\n",
    "        \"\"\" 학습률을 W&B에 로깅 \"\"\"\n",
    "        if self.run:\n",
    "            try:\n",
    "                 # 옵티마이저 종류에 따라 학습률 접근 방식이 다를 수 있음 (일반적인 경우)\n",
    "                if optimizer and optimizer.param_groups:\n",
    "                     lr = optimizer.param_groups[0]['lr']\n",
    "                     wandb.log({\"learning_rate\": lr}, step=step)\n",
    "                else:\n",
    "                     print(\"경고: 유효한 옵티마이저가 아니거나 param_groups가 없어 학습률 로깅 불가\")\n",
    "            except Exception as e:\n",
    "                print(f\"W&B 학습률 로깅 중 오류: {e}\")\n",
    "\n",
    "\n",
    "    # log_gradients 와 log_model_weights는 wandb.watch(log=\"all\") 사용 시 자동 로깅될 수 있음\n",
    "    # 수동 로깅이 필요하다면 아래 함수 사용\n",
    "    def log_gradients_manual(self, model, step):\n",
    "        \"\"\" 그라디언트 통계를 수동으로 W&B에 로깅 \"\"\"\n",
    "        if self.run:\n",
    "            grads = {f\"gradients/{name}\": wandb.Histogram(param.grad.cpu())\n",
    "                     for name, param in model.named_parameters()\n",
    "                     if param.requires_grad and param.grad is not None}\n",
    "            if grads:\n",
    "                try:\n",
    "                    wandb.log(grads, step=step)\n",
    "                except Exception as e:\n",
    "                    print(f\"W&B 그라디언트 로깅 중 오류: {e}\")\n",
    "\n",
    "    def log_weights_manual(self, model, step):\n",
    "        \"\"\" 모델 가중치 통계를 수동으로 W&B에 로깅 \"\"\"\n",
    "        if self.run:\n",
    "            weights = {f\"weights/{name}\": wandb.Histogram(param.data.cpu())\n",
    "                       for name, param in model.named_parameters()\n",
    "                       if param.requires_grad}\n",
    "            if weights:\n",
    "                try:\n",
    "                    wandb.log(weights, step=step)\n",
    "                except Exception as e:\n",
    "                    print(f\"W&B 가중치 로깅 중 오류: {e}\")\n",
    "\n",
    "\n",
    "    def log_artifact(self, name, type, description, path):\n",
    "        \"\"\" 아티팩트를 W&B에 로깅 \"\"\"\n",
    "        if self.run and os.path.exists(path): # 파일 존재 확인 추가\n",
    "            try:\n",
    "                artifact = wandb.Artifact(name, type=type, description=description)\n",
    "                artifact.add_file(path)\n",
    "                wandb.log_artifact(artifact)\n",
    "            except Exception as e:\n",
    "                print(f\"W&B 아티팩트 로깅 중 오류: {e}\")\n",
    "        elif not os.path.exists(path):\n",
    "             print(f\"경고: 아티팩트 파일 '{path}'를 찾을 수 없어 로깅을 건너<0xEB>고 뜁니다.\")\n",
    "\n",
    "\n",
    "    def finish(self):\n",
    "        \"\"\" W&B 실행 종료 \"\"\"\n",
    "        if self.run:\n",
    "            try:\n",
    "                wandb.finish()\n",
    "                print(\"W&B Run 종료.\")\n",
    "                self.run = None # 종료 후 run 객체 None 설정\n",
    "            except Exception as e:\n",
    "                print(f\"W&B 종료 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f564d",
   "metadata": {},
   "source": [
    "## 8. 모델 초기화 및 확인\n",
    "\n",
    "사전 학습된 ResNet18 모델을 로드하고 마지막 레이어를 수정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3493c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "# pretrained=True 대신 weights 사용 권장 (최신 torchvision)\n",
    "try:\n",
    "    weights = models.ResNet18_Weights.DEFAULT # DEFAULT는 ImageNet 1K v1 가중치\n",
    "    model = models.resnet18(weights=weights)\n",
    "    train_transform = weights.transforms() # 사전 학습된 가중치에 맞는 변환 사용 권장\n",
    "    val_transform = weights.transforms()\n",
    "    print(\"최신 방식으로 ResNet18 가중치 로드 및 변환 사용.\")\n",
    "except AttributeError:\n",
    "    print(\"경고: 최신 ResNet18_Weights 방식 사용 불가. pretrained=True 사용.\")\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    # 이전 변환 방식 유지 (위 셀에서 정의된 것 사용)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "# 마지막 레이어(Fully Connected)를 CIFAR-10 클래스 수(10)에 맞게 교체\n",
    "model.fc = nn.Linear(num_ftrs, len(classes))\n",
    "\n",
    "# --- 전이 학습 전략 ---\n",
    "# 옵션 1: 마지막 레이어만 학습 (Feature Extractor) - 기본\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters(): # 새로 추가된 FC 레이어만 학습\n",
    "    param.requires_grad = True\n",
    "print(\"전이 학습 전략: 마지막 레이어만 학습 (Feature Extractor)\")\n",
    "\n",
    "# 옵션 2: 전체 모델 미세 조정 (Fine-tuning) - 필요시 주석 해제\n",
    "# print(\"전이 학습 전략: 전체 모델 미세 조정 (Fine-tuning)\")\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# 모델을 지정된 장치로 이동\n",
    "device = torch.device(config[\"device\"])\n",
    "model = model.to(device)\n",
    "\n",
    "# 학습 가능한 파라미터 수 계산 함수\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"모델 아키텍처: {config['model']}\")\n",
    "print(f\"학습 가능한 파라미터 수: {count_parameters(model):,}\")\n",
    "# print(f\"모델 전체 파라미터 수: {sum(p.numel() for p in model.parameters()):,}\") # 전체 파라미터\n",
    "print(f\"마지막 FC 레이어: Input={num_ftrs}, Output={len(classes)}\")\n",
    "\n",
    "\n",
    "# 모델 구조 시각화 (선택 사항)\n",
    "# 모델이 복잡하면 시각화가 어려울 수 있음\n",
    "print(\"모델 구조:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0aeb6d",
   "metadata": {},
   "source": [
    "## 9. 학습 함수 정의\n",
    "\n",
    "모델을 학습시키는 함수를 정의합니다. 이 함수는 W&B 모니터링을 활용하여 학습 과정을 추적합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c069b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, monitor, num_epochs, device, classes):\n",
    "    \"\"\"\n",
    "    W&B 모니터링을 사용하여 모델 학습 및 검증\n",
    "\n",
    "    Args:\n",
    "        (이전과 동일)\n",
    "\n",
    "    Returns:\n",
    "        history (dict): 에폭별 학습/검증 손실 및 정확도 기록\n",
    "        best_model_path (str): 최고 검증 정확도를 달성한 모델의 저장 경로\n",
    "    \"\"\"\n",
    "    best_val_acc = 0.0\n",
    "    best_model_path = 'best_model_checkpoint.pth' # 체크포인트 파일명\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    # W&B가 초기화되었는지 확인\n",
    "    if not monitor or not monitor.run:\n",
    "         print(\"경고: W&B 모니터가 초기화되지 않아 로깅 없이 학습을 진행합니다.\")\n",
    "         use_wandb = False\n",
    "    else:\n",
    "         use_wandb = True\n",
    "\n",
    "    total_steps = 0 # 전체 배치 스텝 카운트\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- 학습 단계 ---\n",
    "        model.train() # 모델을 학습 모드로 설정\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        processed_samples = 0\n",
    "\n",
    "        # tqdm으로 진행률 표시\n",
    "        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', leave=False)\n",
    "\n",
    "        for inputs, labels in train_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 옵티마이저 그래디언트 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 예측 (가장 높은 확률을 가진 클래스 인덱스)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # 역전파 및 옵티마이저 스텝\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 통계 업데이트\n",
    "            batch_loss = loss.item() * inputs.size(0) # 배치 손실 (평균 * 배치크기)\n",
    "            batch_corrects = torch.sum(preds == labels.data)\n",
    "            running_loss += batch_loss\n",
    "            running_corrects += batch_corrects\n",
    "            processed_samples += inputs.size(0)\n",
    "            total_steps += 1\n",
    "\n",
    "            # tqdm 진행률 표시줄 업데이트 (배치 평균 손실/정확도)\n",
    "            train_bar.set_postfix(loss=f\"{batch_loss/inputs.size(0):.4f}\", acc=f\"{batch_corrects.double()/inputs.size(0)*100:.2f}%\")\n",
    "\n",
    "            # 배치 단위 메트릭 W&B 로깅 (선택 사항, 너무 자주하면 느려짐)\n",
    "            if use_wandb and total_steps % 100 == 0: # 예: 100 스텝마다 로깅\n",
    "                 monitor.log_metrics({\n",
    "                     'batch_train_loss': batch_loss / inputs.size(0),\n",
    "                     'batch_train_acc': batch_corrects.double() / inputs.size(0) * 100\n",
    "                 }, step=total_steps)\n",
    "\n",
    "\n",
    "        # 에폭 학습 통계 계산\n",
    "        epoch_train_loss = running_loss / processed_samples\n",
    "        epoch_train_acc = running_corrects.double() / processed_samples * 100\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "\n",
    "        # --- 검증 단계 ---\n",
    "        model.eval() # 모델을 평가 모드로 설정\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        processed_samples = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        val_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]', leave=False)\n",
    "\n",
    "        with torch.no_grad(): # 검증 시에는 그래디언트 계산 비활성화\n",
    "            for inputs, labels in val_bar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                processed_samples += inputs.size(0)\n",
    "\n",
    "                # 혼동 행렬 계산을 위해 예측과 실제 레이블 저장\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                # tqdm 진행률 표시줄 업데이트 (배치 평균 손실/정확도)\n",
    "                val_bar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{torch.sum(preds == labels.data).double()/inputs.size(0)*100:.2f}%\")\n",
    "\n",
    "        # 에폭 검증 통계 계산\n",
    "        epoch_val_loss = running_loss / processed_samples\n",
    "        epoch_val_acc = running_corrects.double() / processed_samples * 100\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "        print(f\"\n",
    "Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.2f}%\")\n",
    "        print(f\"Val Loss:   {epoch_val_loss:.4f} Acc: {epoch_val_acc:.2f}%\")\n",
    "\n",
    "        # --- W&B 로깅 (에폭 단위) ---\n",
    "        if use_wandb:\n",
    "            log_data = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': epoch_train_loss,\n",
    "                'train_acc': epoch_train_acc,\n",
    "                'val_loss': epoch_val_loss,\n",
    "                'val_acc': epoch_val_acc\n",
    "            }\n",
    "            monitor.log_metrics(log_data, step=epoch) # step을 epoch 기준으로 로깅\n",
    "            monitor.log_learning_rate(optimizer, epoch) # 학습률 로깅\n",
    "\n",
    "            # 혼동 행렬 로깅 (예: 마지막 에폭 또는 주기적으로)\n",
    "            if epoch == num_epochs - 1: # 마지막 에폭에만 로깅\n",
    "                 monitor.log_confusion_matrix(np.array(all_labels), np.array(all_preds), classes)\n",
    "\n",
    "            # 예시 이미지 로깅 (예: 마지막 에폭 또는 주기적으로)\n",
    "            if epoch == num_epochs - 1:\n",
    "                 # 검증 데이터의 마지막 배치 사용\n",
    "                 monitor.log_images(inputs[:8], name=\"validation_samples\", captions=[f\"Pred:{classes[p]}, True:{classes[l]}\" for p, l in zip(all_preds[-8:], all_labels[-8:])])\n",
    "\n",
    "\n",
    "        # 최고 검증 정확도 모델 저장\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            print(f\"Validation accuracy improved ({best_val_acc:.2f}% -> {epoch_val_acc:.2f}%). Saving model...\")\n",
    "            best_val_acc = epoch_val_acc\n",
    "            # 모델 상태 저장 (state_dict)\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Model saved to {best_model_path}\")\n",
    "            # W&B 아티팩트로 모델 저장 (선택 사항)\n",
    "            if use_wandb:\n",
    "                 monitor.log_artifact(\n",
    "                     'best_model', # 아티팩트 논리적 이름\n",
    "                     'model',      # 아티팩트 타입\n",
    "                     f'Epoch {epoch+1} best model with val_acc {best_val_acc:.2f}%',\n",
    "                     best_model_path\n",
    "                 )\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "\n",
    "    print(f\"\n",
    "학습 완료. 최고 검증 정확도: {best_val_acc:.2f}%\")\n",
    "    return history, best_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d9763",
   "metadata": {},
   "source": [
    "## 10. 옵티마이저 및 손실 함수 초기화\n",
    "\n",
    "모델 학습에 필요한 옵티마이저와 손실 함수를 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 선택 및 초기화\n",
    "if config[\"optimizer\"].lower() == \"adam\":\n",
    "    # 마지막 레이어의 파라미터만 학습 대상으로 전달\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=config[\"learning_rate\"])\n",
    "elif config[\"optimizer\"].lower() == \"sgd\":\n",
    "    optimizer = optim.SGD(model.fc.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
    "else:\n",
    "    print(f\"경고: 지원되지 않는 옵티마이저 '{config['optimizer']}'. Adam을 기본값으로 사용합니다.\")\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "\n",
    "# 손실 함수 초기화\n",
    "if config[\"loss\"].lower() == \"crossentropy\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "     print(f\"경고: 지원되지 않는 손실 함수 '{config['loss']}'. CrossEntropyLoss를 기본값으로 사용합니다.\")\n",
    "     criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "print(f\"옵티마이저: {type(optimizer).__name__} (학습률: {config['learning_rate']})\")\n",
    "print(f\"손실 함수: {type(criterion).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ffce7",
   "metadata": {},
   "source": [
    "## 11. Weights & Biases 설정\n",
    "\n",
    "Weights & Biases 모니터링을 설정합니다. 이 부분을 실행하면 W&B에 로그인해야 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W&B 모니터 초기화\n",
    "# wandb.login() # 주피터 노트북 환경에서 명시적으로 로그인 필요 시 주석 해제\n",
    "monitor = WandbMonitor(\"pytorch-cifar10-wandb\", config) # 프로젝트 이름 지정\n",
    "\n",
    "# 모델 파라미터 및 그라디언트 모니터링 시작 (WandbMonitor 내부에서 처리)\n",
    "if monitor.run: # monitor가 성공적으로 초기화되었을 때만 watch 실행\n",
    "    monitor.watch_model(model, log_freq=100) # 100 스텝마다 로깅\n",
    "\n",
    "    print(\"Weights & Biases 모니터링 설정 완료.\")\n",
    "    print(f\"Run Name: {monitor.run.name}\")\n",
    "    print(f\"W&B 대시보드에서 '{monitor.run.project}/{monitor.run.id}' 를 확인하세요.\")\n",
    "else:\n",
    "    print(\"W&B 모니터링 설정 실패. 로깅 없이 진행됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e437c",
   "metadata": {},
   "source": [
    "## 12. 모델 학습 시작\n",
    "\n",
    "모델 학습을 시작합니다. 이 과정은 설정에 따라 시간이 소요될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35885bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 실행\n",
    "# 필요한 모든 변수(model, loaders, criterion, optimizer 등)가 정의되어 있어야 함\n",
    "try:\n",
    "    history, best_model_path = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        monitor=monitor, # WandbMonitor 인스턴스 전달\n",
    "        num_epochs=config[\"epochs\"],\n",
    "        device=device,\n",
    "        classes=classes\n",
    "    )\n",
    "    print(f\"\n",
    "학습 완료! 최고 성능 모델이 '{best_model_path}'에 저장되었습니다.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"오류: 학습 시작 전 필요한 변수가 정의되지 않았습니다. ({e})\")\n",
    "    print(\"이전 셀들이 모두 성공적으로 실행되었는지 확인하세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"학습 중 예상치 못한 오류 발생: {e}\")\n",
    "    # 오류 발생 시에도 W&B run 종료 시도\n",
    "    if 'monitor' in locals() and monitor.run:\n",
    "        monitor.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7d5cc",
   "metadata": {},
   "source": [
    "## 13. 학습 결과 분석\n",
    "\n",
    "학습이 완료된 후 성능을 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4001f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 시각화 및 분석 (history 변수가 정상적으로 반환되었을 경우)\n",
    "if 'history' in locals() and history['val_acc']: # history가 있고 검증 정확도 기록이 있을 때\n",
    "    best_epoch_idx = np.argmax(history['val_acc']) # 최고 정확도의 인덱스 (0부터 시작)\n",
    "    best_val_acc = history['val_acc'][best_epoch_idx]\n",
    "    best_epoch_num = best_epoch_idx + 1 # 에폭 번호 (1부터 시작)\n",
    "\n",
    "    epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # 손실 그래프\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history['train_loss'], 'bo-', label='학습 손실')\n",
    "    plt.plot(epochs_range, history['val_loss'], 'ro-', label='검증 손실')\n",
    "    plt.axvline(best_epoch_num, color='g', linestyle='--', label=f'최고 성능 에폭 ({best_epoch_num})')\n",
    "    plt.title('학습 및 검증 손실')\n",
    "    plt.xlabel('에폭')\n",
    "    plt.ylabel('손실')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 정확도 그래프\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history['train_acc'], 'bo-', label='학습 정확도')\n",
    "    plt.plot(epochs_range, history['val_acc'], 'ro-', label='검증 정확도')\n",
    "    plt.axvline(best_epoch_num, color='g', linestyle='--', label=f'최고 성능 에폭 ({best_epoch_num})')\n",
    "    plt.title('학습 및 검증 정확도')\n",
    "    plt.xlabel('에폭')\n",
    "    plt.ylabel('정확도 (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.suptitle('학습 결과 분석', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # suptitle과의 간격 조정\n",
    "    plt.show()\n",
    "\n",
    "    # 최고 성능 출력\n",
    "    print(f\"\n",
    "최고 성능 (에폭 {best_epoch_num}):\")\n",
    "    print(f\"  - 검증 정확도: {best_val_acc:.2f}%\")\n",
    "    print(f\"  - 검증 손실: {history['val_loss'][best_epoch_idx]:.4f}\")\n",
    "    print(f\"  - 학습 정확도: {history['train_acc'][best_epoch_idx]:.2f}%\")\n",
    "    print(f\"  - 학습 손실: {history['train_loss'][best_epoch_idx]:.4f}\")\n",
    "else:\n",
    "    print(\"학습 기록(history)이 없거나 유효하지 않아 결과를 분석할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8c133",
   "metadata": {},
   "source": [
    "## 14. 최고 성능 모델 평가\n",
    "\n",
    "저장된 최고 성능 모델을 로드하고 검증 데이터셋에 대해 최종 평가를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 성능 모델 로드 및 평가\n",
    "if 'best_model_path' in locals() and os.path.exists(best_model_path):\n",
    "    print(f\"최고 성능 모델 '{best_model_path}' 로드 중...\")\n",
    "    # 모델 구조 다시 정의 (저장된 state_dict와 구조가 일치해야 함)\n",
    "    eval_model = models.resnet18(weights=None) # 가중치 없이 구조만 가져옴\n",
    "    num_ftrs = eval_model.fc.in_features\n",
    "    eval_model.fc = nn.Linear(num_ftrs, len(classes))\n",
    "\n",
    "    # state_dict 로드\n",
    "    eval_model.load_state_dict(torch.load(best_model_path, map_location=device)) # map_location으로 장치 지정\n",
    "    eval_model = eval_model.to(device)\n",
    "    eval_model.eval() # 평가 모드 설정\n",
    "    print(\"모델 로드 완료.\")\n",
    "\n",
    "    # 검증 데이터셋에서 성능 평가\n",
    "    final_correct = 0\n",
    "    final_total = 0\n",
    "    final_predictions = []\n",
    "    final_true_labels = []\n",
    "\n",
    "    print(\"최종 모델 평가 시작...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"최종 모델 평가\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = eval_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            final_total += labels.size(0)\n",
    "            final_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # 예측 및 실제 레이블 저장 (혼동 행렬, 클래스별 정확도용)\n",
    "            final_predictions.extend(predicted.cpu().numpy())\n",
    "            final_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 최종 정확도 계산\n",
    "    final_accuracy = 100 * final_correct / final_total\n",
    "    print(f'\n",
    "최고 성능 모델의 최종 검증 정확도: {final_accuracy:.2f}%')\n",
    "\n",
    "    # 클래스별 정확도 계산\n",
    "    class_correct = np.zeros(len(classes))\n",
    "    class_total = np.zeros(len(classes))\n",
    "    for i in range(len(final_true_labels)):\n",
    "        label = final_true_labels[i]\n",
    "        pred = final_predictions[i]\n",
    "        if label == pred:\n",
    "            class_correct[label] += 1\n",
    "        class_total[label] += 1\n",
    "\n",
    "    # 클래스별 정확도 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # 0으로 나누는 경우 방지 (해당 클래스 샘플이 없을 경우)\n",
    "    class_accuracies = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "                        for i in range(len(classes))]\n",
    "    plt.bar(range(len(classes)), class_accuracies, align='center', alpha=0.7, color='skyblue')\n",
    "    plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
    "    plt.ylabel('정확도 (%)')\n",
    "    plt.title('최고 성능 모델의 클래스별 정확도')\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # 막대 위에 정확도 값 표시\n",
    "    for i, v in enumerate(class_accuracies):\n",
    "        plt.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.ylim(0, 105) # y축 범위 살짝 늘리기\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # W&B에 최종 결과 로깅 (선택 사항)\n",
    "    if 'monitor' in locals() and monitor.run:\n",
    "         monitor.log_metrics({\n",
    "             \"final_val_accuracy\": final_accuracy,\n",
    "             \"class_accuracies\": wandb.Table(data=[[cls, acc] for cls, acc in zip(classes, class_accuracies)],\n",
    "                                              columns=[\"Class\", \"Accuracy\"])\n",
    "         })\n",
    "         # 최종 혼동 행렬도 로깅 가능\n",
    "         monitor.log_confusion_matrix(np.array(final_true_labels), np.array(final_predictions), classes)\n",
    "\n",
    "else:\n",
    "    print(\"최고 성능 모델 경로(best_model_path)를 찾을 수 없거나 파일이 존재하지 않습니다.\")\n",
    "    print(\"모델 평가를 건너<0xEB>고 뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452e72f",
   "metadata": {},
   "source": [
    "## 15. 예측 시각화\n",
    "\n",
    "검증 데이터셋에서 몇 가지 예시 이미지에 대한 최고 성능 모델의 예측을 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db92f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 시각화 함수 정의 (이전 셀에서 정의됨, 여기서는 실행만)\n",
    "if 'eval_model' in locals(): # 평가 모델이 로드되었는지 확인\n",
    "    print(\"최고 성능 모델을 사용한 예측 시각화:\")\n",
    "    # visualize_predictions 함수는 이전에 정의되었다고 가정\n",
    "    # 이 함수 내부에서 모델, 로더, 클래스, 샘플 수를 인자로 받음\n",
    "    # visualize_samples 함수와 유사하지만 예측 결과도 함께 표시\n",
    "    def visualize_model_predictions(model, dataloader, classes, device, num_samples=8):\n",
    "        model.eval()\n",
    "        images, labels = next(iter(dataloader))\n",
    "        images, labels = images[:num_samples], labels[:num_samples]\n",
    "        images_gpu = images.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images_gpu)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        # 역정규화\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "        images_denorm = images * std + mean\n",
    "        images_denorm = torch.clamp(images_denorm, 0, 1)\n",
    "\n",
    "        fig, axes = plt.subplots(2, num_samples // 2, figsize=(16, 8))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, (img, label, pred, prob) in enumerate(zip(images_denorm, labels, preds.cpu(), probs.cpu())):\n",
    "            img_display = img.permute(1, 2, 0).numpy()\n",
    "            axes[i].imshow(img_display)\n",
    "            is_correct = label == pred\n",
    "            title_color = 'green' if is_correct else 'red'\n",
    "            pred_prob = prob[pred].item() # 예측된 클래스의 확률\n",
    "            axes[i].set_title(f\"실제: {classes[label]}\n",
    "예측: {classes[pred]} ({pred_prob:.2f})\",\n",
    "                              color=title_color, fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 함수 실행\n",
    "    visualize_model_predictions(eval_model, val_loader, classes, device)\n",
    "\n",
    "else:\n",
    "    print(\"평가 모델(eval_model)이 로드되지 않아 예측 시각화를 건너<0xEB>고 뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c12a8f",
   "metadata": {},
   "source": [
    "## 16. 혼동 행렬 시각화\n",
    "\n",
    "최고 성능 모델의 예측 결과에 대한 혼동 행렬을 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화 (sklearn, seaborn 사용)\n",
    "if 'final_true_labels' in locals() and 'final_predictions' in locals():\n",
    "    try:\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sns\n",
    "\n",
    "        conf_mat = confusion_matrix(final_true_labels, final_predictions)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=classes, yticklabels=classes, annot_kws={\"size\": 10})\n",
    "        plt.xlabel('예측된 레이블', fontsize=12)\n",
    "        plt.ylabel('실제 레이블', fontsize=12)\n",
    "        plt.title('혼동 행렬 (Confusion Matrix)', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 정규화된 혼동 행렬 (클래스별 비율)\n",
    "        conf_mat_norm = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "        conf_mat_norm = np.nan_to_num(conf_mat_norm) # NaN 값을 0으로 처리\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_mat_norm, annot=True, fmt='.2f', cmap='viridis', # 다른 컬러맵 사용 예시\n",
    "                    xticklabels=classes, yticklabels=classes, annot_kws={\"size\": 10})\n",
    "        plt.xlabel('예측된 레이블', fontsize=12)\n",
    "        plt.ylabel('실제 레이블', fontsize=12)\n",
    "        plt.title('정규화된 혼동 행렬 (Normalized Confusion Matrix)', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"오류: 혼동 행렬 시각화를 위해 scikit-learn과 seaborn 라이브러리가 필요합니다.\")\n",
    "        print(\"!pip install scikit-learn seaborn\")\n",
    "    except Exception as e:\n",
    "        print(f\"혼동 행렬 시각화 중 오류 발생: {e}\")\n",
    "else:\n",
    "    print(\"혼동 행렬을 계산하기 위한 예측 결과(final_predictions) 또는 실제 레이블(final_true_labels)이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd53e3f9",
   "metadata": {},
   "source": [
    "## 17. 모델 해석 (Grad-CAM)\n",
    "\n",
    "Grad-CAM 기법을 사용하여 모델이 이미지의 어떤 영역에 주목하여 예측하는지 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002977b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM 시각화\n",
    "# 필요한 라이브러리 설치 확인\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    grad_cam_available = True\n",
    "except ImportError:\n",
    "    print(\"경고: Grad-CAM 시각화를 위해 'grad-cam' 라이브러리가 필요합니다.\")\n",
    "    print(\"!pip install grad-cam\")\n",
    "    grad_cam_available = False\n",
    "\n",
    "if grad_cam_available and 'eval_model' in locals():\n",
    "    print(\"Grad-CAM 시각화 생성 중...\")\n",
    "    # Grad-CAM 대상 레이어 선택 (모델 구조에 따라 변경 필요)\n",
    "    # 예: ResNet18의 마지막 conv 블록의 마지막 레이어\n",
    "    try:\n",
    "        target_layers = [eval_model.layer4[-1]] # ResNet 구조에 따라 변경\n",
    "    except AttributeError:\n",
    "         print(\"오류: 모델 구조에서 'layer4'를 찾을 수 없습니다. 대상 레이어를 확인하세요.\")\n",
    "         target_layers = None # 대상 레이어 설정 실패\n",
    "\n",
    "    if target_layers:\n",
    "        # 이미지 가져오기 (검증 데이터 로더 사용, num_samples=4)\n",
    "        dataiter = iter(val_loader)\n",
    "        images, labels = next(dataiter)\n",
    "        images_selected = images[:4].to(device) # GPU로 이동\n",
    "        labels_selected = labels[:4]\n",
    "\n",
    "        # 원본 이미지 준비 (역정규화)\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
    "        images_denorm = images_selected.clone() * std + mean\n",
    "        images_denorm = torch.clamp(images_denorm, 0, 1)\n",
    "\n",
    "        # Grad-CAM 객체 초기화\n",
    "        cam = GradCAM(model=eval_model, target_layers=target_layers, use_cuda=torch.cuda.is_available())\n",
    "\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(16, 8)) # 가로 크기 늘림\n",
    "\n",
    "        for i, (img_tensor, label) in enumerate(zip(images_selected, labels_selected)):\n",
    "            # 원본 이미지 표시 (CPU로 이동 및 채널 변경)\n",
    "            img_np = images_denorm[i].cpu().permute(1, 2, 0).numpy()\n",
    "            axes[0, i].imshow(img_np)\n",
    "            axes[0, i].set_title(f'원본: {classes[label]}')\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "            # Grad-CAM 계산 (개별 이미지에 대해)\n",
    "            input_tensor = img_tensor.unsqueeze(0) # 배치 차원 추가\n",
    "            # 타겟 설정: 분류 모델의 경우 예측된 클래스를 타겟으로 하거나 실제 레이블을 타겟으로 할 수 있음\n",
    "            # targets = [ClassifierOutputTarget(label.item())] # 실제 레이블 기준\n",
    "            # 또는 모델 예측 기준:\n",
    "            with torch.no_grad():\n",
    "                 output = eval_model(input_tensor)\n",
    "                 _, pred_idx = torch.max(output, 1)\n",
    "            targets = [ClassifierOutputTarget(pred_idx.item())] # 예측 레이블 기준\n",
    "\n",
    "\n",
    "            grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "            grayscale_cam = grayscale_cam[0, :] # 배치 차원 제거, 결과는 (H, W) 형태\n",
    "\n",
    "            # Grad-CAM 오버레이 및 표시\n",
    "            try:\n",
    "                cam_image = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "                axes[1, i].imshow(cam_image)\n",
    "                axes[1, i].set_title(f'Grad-CAM (예측: {classes[pred_idx.item()]})')\n",
    "                axes[1, i].axis('off')\n",
    "            except Exception as vis_e:\n",
    "                 print(f\"Grad-CAM 시각화 중 오류 (이미지 {i}): {vis_e}\")\n",
    "                 axes[1, i].set_title('Grad-CAM 시각화 오류')\n",
    "                 axes[1, i].axis('off')\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Grad-CAM: 모델이 주목하는 영역 시각화', fontsize=16, y=1.03)\n",
    "        plt.show()\n",
    "\n",
    "elif not grad_cam_available:\n",
    "    print(\"Grad-CAM 라이브러리가 없어 시각화를 건너<0xEB>고 뜁니다.\")\n",
    "else: # 'eval_model'이 없는 경우\n",
    "    print(\"평가 모델(eval_model)이 로드되지 않아 Grad-CAM 시각화를 건너<0xEB>고 뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ed575",
   "metadata": {},
   "source": [
    "## 18. 모니터링 종료\n",
    "\n",
    "Weights & Biases 모니터링 실행을 종료합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W&B 모니터링 종료\n",
    "if 'monitor' in locals() and monitor.run: # monitor 객체가 있고, run이 활성 상태일 때만 종료 시도\n",
    "    monitor.finish()\n",
    "else:\n",
    "    print(\"W&B 모니터가 초기화되지 않았거나 이미 종료된 상태입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ecf51",
   "metadata": {},
   "source": [
    "## 19. 커스텀 이미지 예측\n",
    "\n",
    "로컬 또는 업로드된 이미지에 대해 학습된 모델로 예측을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659502d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 이미지 예측 함수 정의 (이전 셀에서 정의됨, 여기서는 실행만)\n",
    "\n",
    "# --- 사용자 입력 또는 파일 업로드를 통해 이미지 경로 설정 ---\n",
    "# 예시 1: 직접 경로 입력\n",
    "# custom_image_path = \"your_image.jpg\" # 실제 이미지 경로로 변경하세요.\n",
    "\n",
    "# 예시 2: Colab 환경에서 파일 업로드\n",
    "# try:\n",
    "#     from google.colab import files\n",
    "#     uploaded = files.upload()\n",
    "#     if uploaded:\n",
    "#         custom_image_path = list(uploaded.keys())[0]\n",
    "#         print(f\"업로드된 파일: {custom_image_path}\")\n",
    "#     else:\n",
    "#         custom_image_path = None\n",
    "#         print(\"파일이 업로드되지 않았습니다.\")\n",
    "# except ImportError:\n",
    "#      custom_image_path = None\n",
    "#      print(\"Colab 환경이 아니므로 파일 업로드를 건너<0xEB>고 뜁니다. 직접 경로를 지정하세요.\")\n",
    "\n",
    "custom_image_path = None # 기본적으로 경로 없음으로 시작\n",
    "\n",
    "# --- 예측 실행 ---\n",
    "if custom_image_path and 'eval_model' in locals() and os.path.exists(custom_image_path):\n",
    "    print(f\"\n",
    "'{custom_image_path}' 이미지 예측 수행:\")\n",
    "    # predict_image 함수는 이전에 정의되었다고 가정\n",
    "    # 필요한 인자: 모델, 이미지 경로, 클래스 리스트, 장치\n",
    "    def predict_custom_image(model, image_path, classes, device, transform=None):\n",
    "        \"\"\" 커스텀 이미지 예측 및 시각화 함수 (재정의 또는 이전 함수 사용) \"\"\"\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"오류: 이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"오류: 이미지 로딩 중 오류 발생: {e}\")\n",
    "            return\n",
    "\n",
    "        if transform is None:\n",
    "            # 기본 검증용 변환 사용\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "        image_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "            score, pred_idx = torch.max(output, 1)\n",
    "            predicted_class_idx = pred_idx.item()\n",
    "\n",
    "        # 결과 시각화\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img); plt.title('입력 이미지'); plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        top_5_prob, top_5_idx = torch.topk(probabilities, 5)\n",
    "        top_5_prob = top_5_prob.cpu().numpy()\n",
    "        top_5_idx = top_5_idx.cpu().numpy()\n",
    "        y_pos = np.arange(len(top_5_idx))\n",
    "        plt.barh(y_pos, top_5_prob, align='center', color='lightcoral');\n",
    "        plt.yticks(y_pos, [classes[i] for i in top_5_idx]); plt.xlabel('확률');\n",
    "        plt.title('상위 5개 예측'); plt.gca().invert_yaxis();\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "        predicted_class_name = classes[predicted_class_idx]\n",
    "        confidence = probabilities[predicted_class_idx].item()\n",
    "        print(f\"\n",
    "예측 결과: {predicted_class_name} (확신도: {confidence:.2%})\")\n",
    "\n",
    "    # 예측 함수 실행\n",
    "    predict_custom_image(eval_model, custom_image_path, classes, device)\n",
    "\n",
    "elif not custom_image_path:\n",
    "    print(\"\n",
    "커스텀 이미지 경로가 지정되지 않았습니다. 예측을 건너<0xEB>고 뜁니다.\")\n",
    "elif 'eval_model' not in locals():\n",
    "     print(\"\n",
    "평가 모델(eval_model)이 로드되지 않아 커스텀 이미지 예측을 건너<0xEB>고 뜁니다.\")\n",
    "elif not os.path.exists(custom_image_path):\n",
    "      print(f\"\n",
    "오류: 지정된 이미지 경로 '{custom_image_path}'를 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7d6cc",
   "metadata": {},
   "source": [
    "## 20. 요약 및 향후 개선 방향\n",
    "\n",
    "최종 학습 결과와 모델 성능을 요약하고, 추가적으로 시도해볼 수 있는 개선 방향을 제시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c26155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 요약 및 향후 개선 방향\n",
    "print(\"=\" * 60)\n",
    "print(\"종합 요약 및 향후 개선 방향\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'config' in locals():\n",
    "    print(\"[학습 설정]\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "else:\n",
    "    print(\"[학습 설정] 정보 없음\")\n",
    "\n",
    "if 'history' in locals() and history['val_acc']:\n",
    "    best_epoch_idx = np.argmax(history['val_acc'])\n",
    "    best_val_acc = history['val_acc'][best_epoch_idx]\n",
    "    print(\"\n",
    "[최고 성능 에폭]\")\n",
    "    print(f\"  - 에폭 번호: {best_epoch_idx + 1}\")\n",
    "    print(f\"  - 검증 정확도: {best_val_acc:.2f}%\")\n",
    "else:\n",
    "    print(\"\n",
    "[최고 성능 에폭] 정보 없음\")\n",
    "\n",
    "if 'final_accuracy' in locals():\n",
    "     print(\"\n",
    "[최종 모델 성능]\")\n",
    "     print(f\"  - 최종 검증 정확도: {final_accuracy:.2f}%\")\n",
    "     if 'class_accuracies' in locals():\n",
    "         print(f\"  - 클래스별 정확도 (평균): {np.mean(class_accuracies):.2f}%\")\n",
    "         print(f\"  - 클래스별 정확도 (최저): {min(class_accuracies):.2f}%\")\n",
    "         print(f\"  - 클래스별 정확도 (최고): {max(class_accuracies):.2f}%\")\n",
    "else:\n",
    "     print(\"\n",
    "[최종 모델 성능] 정보 없음\")\n",
    "\n",
    "\n",
    "print(\"\n",
    "[향후 개선 방향 제안]\")\n",
    "suggestions = [\n",
    "    \"더 많은 에폭으로 학습 진행 또는 조기 종료(Early Stopping) 기준 조정\",\n",
    "    \"데이터 증강(Data Augmentation) 기법 강화 또는 변경 (e.g., AutoAugment, CutMix)\",\n",
    "    \"학습률 스케줄러(Learning Rate Scheduler) 변경 또는 파라미터 튜닝 (e.g., CosineAnnealingLR, OneCycleLR)\",\n",
    "    \"옵티마이저(Optimizer) 변경 또는 파라미터 튜닝 (e.g., AdamW, SGD with Nesterov)\",\n",
    "    \"모델 아키텍처 변경 또는 더 큰 사전 학습 모델 사용 (e.g., ResNet50, EfficientNet, ViT)\",\n",
    "    \"하이퍼파라미터 자동 튜닝 도구 사용 (e.g., Weights & Biases Sweeps, Optuna)\",\n",
    "    \"앙상블(Ensemble) 기법 적용: 여러 모델의 예측 결합\",\n",
    "    \"정규화(Regularization) 기법 추가/조정 (e.g., Label Smoothing, Dropout 비율 변경, Weight Decay 값 조정)\",\n",
    "    \"데이터셋 확장 또는 외부 데이터 활용\",\n",
    "    \"모델 해석 기법(XAI)을 활용한 추가 분석 (e.g., SHAP)\"\n",
    "]\n",
    "for i, suggestion in enumerate(suggestions):\n",
    "    print(f\" {i+1}. {suggestion}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
